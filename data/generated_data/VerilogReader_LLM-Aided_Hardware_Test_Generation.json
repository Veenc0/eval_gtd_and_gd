{
  "summary": "This paper presents VerilogReader, a framework integrating large language models (LLMs) into coverage-directed test generation for hardware verification.  The framework uses \"Coverage Explainer\" and \"DUT Explainer\" modules to improve LLM comprehension of Verilog code and coverage reports, generating test inputs in JSON format. Experiments on a benchmark suite of 24 Verilog designs showed that the LLM significantly outperformed random testing for simple and medium-complexity designs.  However, performance degraded for complex designs exceeding 500 lines of code, highlighting limitations in current LLMs' ability to handle large-scale designs.  Future work will focus on improving the LLM's high-level understanding and potentially integrating it with graph neural networks.\n"
}